{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the webdriver \n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "    first get the webpage https://www.naukri.com/\n",
    "    Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "    Then click the search button.\n",
    "    Then scrape the data for the first 10 jobs results you get.\n",
    "    Finally create a dataframe of the scraped data. Note- All of the above steps have to be done in code. No step is to be done manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Analyst',\n",
       " 'Hiring Data Analysts For E commerce Platform || WFH',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'DA - Urgent Opening For Data Analyst BFSI Domain - Pan India',\n",
       " 'Data Analyst',\n",
       " 'Assistant Vice President - MIS & Reporting ( Business Data Analyst)',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    if i.text is None:\n",
    "        job_title.append(\"--\")\n",
    "    else:\n",
    "         job_title.append(i.text)\n",
    "    \n",
    "job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " '(851 Reviews)',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " '(202 Reviews)',\n",
       " 'Shell India Markets Private Limited',\n",
       " '(621 Reviews)',\n",
       " 'Applied Materials',\n",
       " '(94 Reviews)',\n",
       " 'Tata Consultancy Services Ltd.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-5 Yrs',\n",
       " '5-8 Yrs',\n",
       " '7-10 Yrs',\n",
       " '4-9 Yrs',\n",
       " '5-8 Yrs',\n",
       " '12-18 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-6 Yrs']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>(851 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>(202 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                             company_name  \\\n",
       "0             0-3 Yrs       Inflexion Analytix Private Limited   \n",
       "1             0-2 Yrs  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "2             0-5 Yrs                            (851 Reviews)   \n",
       "3             5-8 Yrs         Allegis Services India Pvt. Ltd.   \n",
       "4            7-10 Yrs                            (202 Reviews)   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "\n",
       "                                           job_title  \n",
       "0    Data Scientist / Data Analyst -Business Analyst  \n",
       "1                                       Data Analyst  \n",
       "2  Hiring Data Analysts For E commerce Platform |...  \n",
       "3                                       Data Analyst  \n",
       "4                                       Data Analyst  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "    first get the webpage https://www.naukri.com/\n",
    "    Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "    Then click the search button.\n",
    "    Then scrape the data for the first 10 jobs results you get.\n",
    "    Finally create a dataframe of the scraped data. Note- 1. All of the above steps have to be done in code. No step is to be done manually. WEB SCR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior / Lead Data Scientist',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Analytics & AI Product Mgmt - Sr. Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist, Modeling',\n",
       " 'Data Scientist - IBM Garage',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'TVS CREDIT SERVICES LIMITED',\n",
       " '(779 Reviews)',\n",
       " 'CES Ltd.',\n",
       " '(85 Reviews)',\n",
       " 'CES Ltd.',\n",
       " '(85 Reviews)',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " '(851 Reviews)',\n",
       " 'Vijaya Management Services']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru, Vadodara, Mumbai (All Areas)',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        full_job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        full_job_description.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior / Lead Data Scientist',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Senior Data Scientist | CES IT LTD | CMMI Level 5',\n",
       " 'Analytics & AI Product Mgmt - Sr. Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist: Computer Vision/Image Analytics',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist, Modeling']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Other',\n",
       " 'Mumbai',\n",
       " 'Mumbai',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru, Vadodara, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'TVS CREDIT SERVICES LIMITED',\n",
       " '(779 Reviews)',\n",
       " 'CES Ltd.',\n",
       " '(85 Reviews)',\n",
       " 'CES Ltd.',\n",
       " '(85 Reviews)',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " '(851 Reviews)',\n",
       " 'Walmart Global Tech India']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '2-7 Yrs',\n",
       " '10-12 Yrs',\n",
       " '0-5 Yrs',\n",
       " '5-7 Yrs',\n",
       " '4-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>(779 Reviews)</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-12 Yrs</td>\n",
       "      <td>(85 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Analytics &amp; AI Product Mgmt - Sr. Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Other</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5-7 Yrs</td>\n",
       "      <td>(85 Reviews)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Senior Data Scientist: Computer Vision/Image A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>(851 Reviews)</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Walmart Global Tech India</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                             company_name  \\\n",
       "0             0-3 Yrs       Inflexion Analytix Private Limited   \n",
       "1             3-8 Yrs              TVS CREDIT SERVICES LIMITED   \n",
       "2             2-7 Yrs                            (779 Reviews)   \n",
       "3             2-7 Yrs                                 CES Ltd.   \n",
       "4           10-12 Yrs                             (85 Reviews)   \n",
       "5             0-5 Yrs                                 CES Ltd.   \n",
       "6             5-7 Yrs                             (85 Reviews)   \n",
       "7             4-7 Yrs  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8            5-10 Yrs                            (851 Reviews)   \n",
       "9             3-7 Yrs                Walmart Global Tech India   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "2  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "3  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                              Other   \n",
       "6                                             Mumbai   \n",
       "7                                             Mumbai   \n",
       "8                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "9  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "\n",
       "                                           job_title  \n",
       "0    Data Scientist / Data Analyst -Business Analyst  \n",
       "1                       Senior / Lead Data Scientist  \n",
       "2  Senior Data Scientist | CES IT LTD | CMMI Level 5  \n",
       "3  Senior Data Scientist | CES IT LTD | CMMI Level 5  \n",
       "4   Analytics & AI Product Mgmt - Sr. Data Scientist  \n",
       "5                           Principal Data Scientist  \n",
       "6                              Senior Data Scientist  \n",
       "7  Senior Data Scientist: Computer Vision/Image A...  \n",
       "8                              Senior Data Scientist  \n",
       "9                    Senior Data Scientist, Modeling  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@id='sc.keyword']\"}\n  (Session info: chrome=90.0.4430.93)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-58551243e103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch_field_designation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//input[@id='sc.keyword']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msearch_field_designation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msearch_field_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//input[@id='sc.location']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msearch_field_location\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Noida\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@id='sc.keyword']\"}\n  (Session info: chrome=90.0.4430.93)\n"
     ]
    }
   ],
   "source": [
    "search_field_designation=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "search_field_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies=driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings=driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "company_ratings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text[0])\n",
    "days_ago[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_sunglass=[]\n",
    "Price_sunglass=[]\n",
    "Discount_sunglass=[]\n",
    "\n",
    "for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:100]:\n",
    "        Brand_sunglass.append(j.text)\n",
    "for k in driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']\")[:100]:\n",
    "        Price_sunglass.append(k.text)\n",
    "for l in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")[:100]:\n",
    "        Discount_sunglass.append(l.text)\n",
    "url=(\"https://www.flipkart.com/search?q=sunglasses&sid=26x&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_10_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_10_na_na_na&as-pos=1&as-type=RECENT&suggestionId=sunglasses%7CSunglasses&requestId=a2e64463-346e-48a4-bde7-6449c21d3f85&as-searchtext=sunglasses\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sung=pd.DataFrame({})\n",
    "sung[\"Brand\"]=Brand_sunglass\n",
    "sung[\"Price\"]=Price_sunglass\n",
    "sung[\"Discount\"]=Discount_sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7:Scrape 100 review data from flipkart.com from iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating_iphone=[]\n",
    "Review_summary=[]\n",
    "full_review=[]\n",
    "for i in range(10):\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "         Rating_iphone.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "         Review_summary.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "         full_review.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone=pd.DataFrame({})\n",
    "iphone[\"Rating\"]=Rating_iphone\n",
    "iphone[\"Review\"]=Review_summary\n",
    "iphone[\"full_reviews\"]=full_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_shoes=[]\n",
    "Product_description=[]\n",
    "Price_shoes=[]\n",
    "discount_shoes=[]\n",
    "for i in range(10):\n",
    "    for j in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        Brand_shoes.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        Product_description.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='product-price']\"):\n",
    "        Price_shoes.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath(\"//span[@class='product-discountPercentage']\"):\n",
    "        discount_shoes.append(m.text)\n",
    "    url=(\"https://www.myntra.com/shoes?plaEnabled=false&rf=Price%3A6612.0_13075.0_6612.0%20TO%2013075.0\")\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes=pd.DataFrame({})\n",
    "shoes[\"Brand\"]=Brand_shoes[:100]\n",
    "shoes[\"Description\"]=Product_description[:100]\n",
    "shoes[\"Price\"]=Price_shoes[:100]\n",
    "shoes[\"Discount\"]=discount_shoes[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM FREAK 2 Basketball</td>\n",
       "      <td>Rs. 8750Rs. 10295(15% OFF)</td>\n",
       "      <td>(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Solid Leather Loafers</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "      <td>(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Perforations Brogues</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "      <td>(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lacoste</td>\n",
       "      <td>Men Sneakers Casual Shoes</td>\n",
       "      <td>Rs. 10500</td>\n",
       "      <td>(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men UltraRide Running Shoes</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "      <td>(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women TriBase Reign 2 Training</td>\n",
       "      <td>Rs. 11999</td>\n",
       "      <td>(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men SKECH-AIR 92 Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VERONA Sneakers</td>\n",
       "      <td>Rs. 7496Rs. 9995(25% OFF)</td>\n",
       "      <td>(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex RS 2.0 Futura Sneakers</td>\n",
       "      <td>Rs. 7199Rs. 7999(10% OFF)</td>\n",
       "      <td>(15% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                     Description  \\\n",
       "0              Nike     Men ZOOM FREAK 2 Basketball   \n",
       "1              ALDO       Men Solid Leather Loafers   \n",
       "2              ALDO        Men Perforations Brogues   \n",
       "3   PUMA Motorsport   Unisex Mercedes Running Shoes   \n",
       "4           Lacoste       Men Sneakers Casual Shoes   \n",
       "..              ...                             ...   \n",
       "95             Puma     Men UltraRide Running Shoes   \n",
       "96     UNDER ARMOUR  Women TriBase Reign 2 Training   \n",
       "97         Skechers       Men SKECH-AIR 92 Sneakers   \n",
       "98             Nike   Women AIR MAX VERONA Sneakers   \n",
       "99             Puma   Unisex RS 2.0 Futura Sneakers   \n",
       "\n",
       "                         Price   Discount  \n",
       "0   Rs. 8750Rs. 10295(15% OFF)  (15% OFF)  \n",
       "1   Rs. 7799Rs. 12999(40% OFF)  (40% OFF)  \n",
       "2   Rs. 7799Rs. 12999(40% OFF)  (40% OFF)  \n",
       "3                     Rs. 7999  (20% OFF)  \n",
       "4                    Rs. 10500  (25% OFF)  \n",
       "..                         ...        ...  \n",
       "95   Rs. 7649Rs. 8999(15% OFF)  (20% OFF)  \n",
       "96                   Rs. 11999  (20% OFF)  \n",
       "97                    Rs. 7999  (20% OFF)  \n",
       "98   Rs. 7496Rs. 9995(25% OFF)  (20% OFF)  \n",
       "99   Rs. 7199Rs. 7999(10% OFF)  (15% OFF)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar =driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys(\"laptops\")\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "for url in UR:\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")\n",
    "        rate.click()\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        Ratings.append(rating.text)\n",
    "    except NoSuchElementException   as e:\n",
    "        Ratings.append(\"NO rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...</td>\n",
       "      <td>77,990</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>99,000</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>36,990</td>\n",
       "      <td>3.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>33,990</td>\n",
       "      <td>2.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>77,975</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>42,499</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...</td>\n",
       "      <td>77,990</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...</td>\n",
       "      <td>79,900</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) HP EliteBook Folio 1040 G2 Laptop (C...</td>\n",
       "      <td>53,590</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price       Ratings\n",
       "0  Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...  77,990    4 out of 5\n",
       "1  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  99,000  4.1 out of 5\n",
       "2  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  36,990  3.2 out of 5\n",
       "3  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  33,990  2.6 out of 5\n",
       "4  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  84,990     NO rating\n",
       "5  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...  77,975  4.4 out of 5\n",
       "6  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...  42,499     NO rating\n",
       "7  Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...  77,990    4 out of 5\n",
       "8  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...  79,900  4.3 out of 5\n",
       "9  (Renewed) HP EliteBook Folio 1040 G2 Laptop (C...  53,590     NO rating"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\"https://www.myntra.com/shoes\". Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6337.0_10225.0_6337.0%20TO%2010225.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Brand                    Short-description  \\\n",
      "0               Nike         Men Solid SKYVE MAX Sneakers   \n",
      "1               Puma                    Men Running Shoes   \n",
      "2   ADIDAS Originals       Men Nite Jogger Fluid Sneakers   \n",
      "3               Nike       AIR ZOOM PEGASUS Running Shoes   \n",
      "4               Nike          Men JORDAN DELTA Basketball   \n",
      "5               Nike         Men KD13 EP Basketball Shoes   \n",
      "6               Nike            Men JOYRIDE Running Shoes   \n",
      "7               Nike           Men React Infinity Running   \n",
      "8               Nike                    Men Running Shoes   \n",
      "9       UNDER ARMOUR            Men Liquify Running Shoes   \n",
      "10   PUMA Motorsport       Men Ferrari Race Kart Sneakers   \n",
      "11              Puma                    Men Running Shoes   \n",
      "12      UNDER ARMOUR        Charged Rogue 2 Wide 2E Shoes   \n",
      "13              Nike            Men JORDAN DELTA Sneakers   \n",
      "14         Cole Haan                     Leather Sneakers   \n",
      "15      Hush Puppies    Men Solid Leather Formal Slip-Ons   \n",
      "16              Nike        LEBRON XVIII Basketball Shoes   \n",
      "17              Nike         Women AIR ZOOM Running Shoes   \n",
      "18              ALDO                         Men Sneakers   \n",
      "19   PUMA Motorsport        Unisex Mercedes Running Shoes   \n",
      "20              Nike        Unisex PHANTOM Football Shoes   \n",
      "21              Nike           Men AIR ZOOM Running Shoes   \n",
      "22              Nike       Women PEGASUS 37 Running Shoes   \n",
      "23              Nike            Women REACT Running Shoes   \n",
      "24              Nike           Women REACT ESCAPE Running   \n",
      "25              Puma           Unisex Futurverse Sneakers   \n",
      "26            Reebok           Men Nano X1 Training Shoes   \n",
      "27              Nike               Women AIR ZOOM Running   \n",
      "28      UNDER ARMOUR           HOVR Sonic 3 Running Shoes   \n",
      "29              Nike         Women AIR ZOOM Running Shoes   \n",
      "30              Puma  Men Mesh Fuse Training Or Gym Shoes   \n",
      "31              Puma          Men UltraRide Running Shoes   \n",
      "32              Puma           Men Velocity Nitro Running   \n",
      "33      UNDER ARMOUR           HOVR Sonic 3 Running Shoes   \n",
      "34          Skechers        Men VIPER COMPETITOR Training   \n",
      "35              Puma        Future Rider Twofold Sneakers   \n",
      "36      UNDER ARMOUR       Women TriBase Reign 2 Training   \n",
      "37              Nike           Men AIR MAX EXCEE Sneakers   \n",
      "38      UNDER ARMOUR        Charged Impulse Running Shoes   \n",
      "39              Nike         Women Air Max Siren Sneakers   \n",
      "40              Puma         Unisex RS-FAST TECH Sneakers   \n",
      "41      Hush Puppies                    Men Formal Derbys   \n",
      "42              Puma          SPEED Orbiter Running Shoes   \n",
      "43      UNDER ARMOUR           Women Charged Breathe TR 2   \n",
      "44            ADIDAS       Men ALPHATORSION Running Shoes   \n",
      "45           Saint G            Men Leather Chelsea Boots   \n",
      "46      UNDER ARMOUR           Women HOVR Rise 2 Training   \n",
      "47              Puma                      Unisex Sneakers   \n",
      "48              Puma           Men Liberate Nitro Running   \n",
      "49              Puma             Unisex RS-X Pop Sneakers   \n",
      "\n",
      "                          Price  \n",
      "0     Rs. 7436Rs. 9295(20% OFF)  \n",
      "1     Rs. 7199Rs. 8999(20% OFF)  \n",
      "2    Rs. 8449Rs. 12999(35% OFF)  \n",
      "3                     Rs. 11495  \n",
      "4                     Rs. 12495  \n",
      "5                     Rs. 12995  \n",
      "6   Rs. 11246Rs. 14995(25% OFF)  \n",
      "7   Rs. 11621Rs. 15495(25% OFF)  \n",
      "8                      Rs. 6495  \n",
      "9                     Rs. 10999  \n",
      "10                     Rs. 9999  \n",
      "11                     Rs. 7499  \n",
      "12                     Rs. 7999  \n",
      "13                    Rs. 10995  \n",
      "14                    Rs. 10999  \n",
      "15                     Rs. 8999  \n",
      "16  Rs. 12320Rs. 14495(15% OFF)  \n",
      "17    Rs. 6996Rs. 9995(30% OFF)  \n",
      "18                     Rs. 9999  \n",
      "19                     Rs. 7999  \n",
      "20    Rs. 6396Rs. 7995(20% OFF)  \n",
      "21  Rs. 10796Rs. 13495(20% OFF)  \n",
      "22    Rs. 7496Rs. 9995(25% OFF)  \n",
      "23   Rs. 8996Rs. 11995(25% OFF)  \n",
      "24    Rs. 6636Rs. 8295(20% OFF)  \n",
      "25                     Rs. 9999  \n",
      "26    Rs. 7499Rs. 9999(25% OFF)  \n",
      "27  Rs. 10796Rs. 13495(20% OFF)  \n",
      "28                    Rs. 10999  \n",
      "29   Rs. 8236Rs. 10295(20% OFF)  \n",
      "30                     Rs. 7999  \n",
      "31    Rs. 7649Rs. 8999(15% OFF)  \n",
      "32                    Rs. 10999  \n",
      "33                    Rs. 10999  \n",
      "34                     Rs. 6999  \n",
      "35                     Rs. 6999  \n",
      "36                    Rs. 11999  \n",
      "37    Rs. 6396Rs. 7995(20% OFF)  \n",
      "38                     Rs. 7999  \n",
      "39    Rs. 6556Rs. 8195(20% OFF)  \n",
      "40                     Rs. 9999  \n",
      "41                     Rs. 9999  \n",
      "42   Rs. 7149Rs. 12999(45% OFF)  \n",
      "43                     Rs. 7999  \n",
      "44    Rs. 6499Rs. 9999(35% OFF)  \n",
      "45   Rs. 11305Rs. 11900(5% OFF)  \n",
      "46                     Rs. 9999  \n",
      "47                     Rs. 6499  \n",
      "48                     Rs. 9999  \n",
      "49    Rs. 8499Rs. 9999(15% OFF)  \n"
     ]
    }
   ],
   "source": [
    "start_page=0\n",
    "end_page=0\n",
    "for page in range(start_page,end_page+1): \n",
    "    nxt_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "    \n",
    "    #creating empty lists\n",
    "    shoe_names=[]\n",
    "    s_desc=[]\n",
    "    short_desc=[]\n",
    "    price=[]\n",
    "    \n",
    "    #for scrapping shoe brand names\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    #for scrapping shoe short-description\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    #for scrapping shoe prices\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in desc:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    #for scrapping the datas from next pages.\n",
    "    if nxt_button.text=='next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "    #creating a dataframe to store above scraped details\n",
    "    df=pd.DataFrame({'Brand': shoe_names,\n",
    "                    'Short-description': short_desc,\n",
    "                    'Price': price})\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
